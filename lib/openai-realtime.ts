// lib/openai-realtime.ts - Implementa√ß√£o completa corrigida com instru√ß√µes atualizadas

export interface RealtimeConfig {
  apiKey: string;
  model?: string;
  voice?: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';
  instructions?: string;
  userLevel: 'Novice' | 'Intermediate' | 'Advanced';
  userName?: string;
}

export interface RealtimeEvent {
  type: string;
  [key: string]: any;
}

export class OpenAIRealtimeService {
  private ws: WebSocket | null = null;
  private config: RealtimeConfig;
  private isConnected = false;
  private audioContext: AudioContext | null = null;
  private mediaStream: MediaStream | null = null;
  private eventListeners: Map<string, Function[]> = new Map();
  private sessionId: string | null = null;
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 3;
  
  // üîä NOVO: Sistema de controle de √°udio para evitar duplica√ß√£o
  private audioQueue: string[] = [];
  private isPlayingAudio = false;
  private currentAudioSource: AudioBufferSourceNode | null = null;
  private audioGainNode: GainNode | null = null;

  constructor(config: RealtimeConfig) {
    this.config = config;
  }

  // üîó Conectar usando implementa√ß√£o corrigida baseada na documenta√ß√£o oficial
  async connect(): Promise<void> {
    return new Promise(async (resolve, reject) => {
      try {
        console.log('üîó [FIXED] Connecting to OpenAI Realtime API...');
        
        // üîë PASSO 1: Obter API key via rota segura
        await this.getAPIKey();
        
        // üåê PASSO 2: Conectar usando m√©todo oficial (subprotocols)
        await this.connectWithSubprotocols(resolve, reject);

      } catch (error: any) {
        console.error('‚ùå [FIXED] Connection error:', error);
        reject(error);
      }
    });
  }

  // üîë Obter API key de forma segura
  private async getAPIKey(): Promise<void> {
    console.log('üîë [FIXED] Getting API key...');
    
    const tokenResponse = await fetch('/api/realtime-token', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        userLevel: this.config.userLevel,
        userName: this.config.userName,
        debug: true
      })
    });

    if (!tokenResponse.ok) {
      const errorData = await tokenResponse.json().catch(() => ({}));
      throw new Error(`Token API failed: ${tokenResponse.status} - ${errorData.error || 'Unknown error'}`);
    }

    const tokenData = await tokenResponse.json();
    if (!tokenData.success) {
      throw new Error(tokenData.error || 'Token request failed');
    }

    this.config.apiKey = tokenData.apiKey;
    console.log('‚úÖ [FIXED] API key obtained successfully');
  }

  // üåê Conectar usando subprotocols (m√©todo oficial para browsers)
  private async connectWithSubprotocols(resolve: Function, reject: Function): Promise<void> {
    try {
      // ‚úÖ Usar modelo testado pela comunidade
      const model = this.config.model || 'gpt-4o-realtime-preview-2024-10-01';
      const wsUrl = `wss://api.openai.com/v1/realtime?model=${model}`;
      
      // ‚úÖ M√âTODO OFICIAL: Autentica√ß√£o via subprotocols (funciona em browsers)
      const subprotocols = [
        "realtime",
        `openai-insecure-api-key.${this.config.apiKey}`,
        "openai-beta.realtime-v1"
      ];

      console.log('üåê [FIXED] WebSocket URL:', wsUrl);
      console.log('üîë [FIXED] Subprotocols:', subprotocols);

      // Criar WebSocket com subprotocols (m√©todo oficial)
      this.ws = new WebSocket(wsUrl, subprotocols);

      // Timeout para conex√£o
      const connectionTimeout = setTimeout(() => {
        if (this.ws) {
          this.ws.close();
          this.ws = null;
        }
        reject(new Error('Connection timeout after 15 seconds'));
      }, 15000);

      // ‚úÖ Event listeners do WebSocket
      this.ws.onopen = () => {
        clearTimeout(connectionTimeout);
        console.log('‚úÖ [FIXED] WebSocket connected successfully using subprotocols!');
        this.isConnected = true;
        this.reconnectAttempts = 0;
        
        // ‚úÖ Inicializar sess√£o ap√≥s conex√£o (m√©todo oficial)
        this.initializeSession();
        resolve();
      };

      this.ws.onmessage = (event) => {
        try {
          console.log('üì• [FIXED] Raw WebSocket message:', event.data);
          this.handleMessage(event.data);
        } catch (error) {
          console.error('‚ùå [FIXED] Error handling message:', error);
        }
      };

      this.ws.onerror = (error) => {
        clearTimeout(connectionTimeout);
        console.error('‚ùå [FIXED] WebSocket error:', error);
        this.isConnected = false;
        
        // An√°lise espec√≠fica do erro
        this.analyzeConnectionError(error, reject);
      };

      this.ws.onclose = (event) => {
        clearTimeout(connectionTimeout);
        console.log('üîå [FIXED] WebSocket closed:', {
          code: event.code,
          reason: event.reason,
          wasClean: event.wasClean
        });
        this.isConnected = false;
        
        // An√°lise de c√≥digos de erro espec√≠ficos
        this.analyzeCloseCode(event, reject);
      };

    } catch (error: any) {
      console.error('‚ùå [FIXED] Failed to create WebSocket:', error);
      reject(error);
    }
  }

  // üîç Analisar erros de conex√£o
  private analyzeConnectionError(error: Event, reject: Function): void {
    const errorMessage = 'WebSocket connection failed';
    
    // Informa√ß√µes de debug
    console.error('‚ùå [FIXED] Connection analysis:', {
      error: error,
      readyState: this.ws?.readyState,
      protocol: this.ws?.protocol,
      url: this.ws?.url
    });

    // Tentar reconectar se n√£o foi um erro de autentica√ß√£o
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      console.log(`üîÑ [FIXED] Attempting reconnect ${this.reconnectAttempts}/${this.maxReconnectAttempts}...`);
      
      setTimeout(() => {
        this.connectWithSubprotocols(() => {}, reject);
      }, 2000 * this.reconnectAttempts);
    } else {
      reject(new Error(`${errorMessage} after ${this.maxReconnectAttempts} attempts. Please check: 1) Your account has Realtime API access, 2) Your billing is active, 3) Network allows WebSocket connections`));
    }
  }

  // üîç Analisar c√≥digos de fechamento
  private analyzeCloseCode(event: CloseEvent, reject?: Function): void {
    let errorMessage = '';
    
    switch (event.code) {
      case 1000:
        console.log('‚úÖ [FIXED] Normal WebSocket closure');
        return;
        
      case 1001:
        console.log('üì± [FIXED] WebSocket closed - going away (normal for page refresh)');
        return;
        
      case 1008:
        errorMessage = 'AUTHENTICATION_FAILED: Invalid API key or your account does not have access to Realtime API';
        break;
        
      case 1003:
        errorMessage = 'PROTOCOL_ERROR: Invalid request format or unsupported data';
        break;
        
      case 1011:
        errorMessage = 'SERVER_ERROR: OpenAI server error - try again later';
        break;
        
      default:
        errorMessage = `WebSocket closed unexpectedly: ${event.code} - ${event.reason || 'Unknown reason'}`;
    }
    
    console.error('‚ùå [FIXED] WebSocket close analysis:', errorMessage);
    
    if (reject) {
      reject(new Error(errorMessage));
    } else {
      this.emit('disconnected', { 
        reason: errorMessage,
        code: event.code 
      });
    }
  }

  // üéØ Inicializar sess√£o (m√©todo oficial simplificado)
  private initializeSession(): void {
    console.log('üéØ [FIXED] Initializing Realtime session...');
    
    // ‚úÖ Configura√ß√£o oficial baseada na documenta√ß√£o e melhores pr√°ticas
    const sessionConfig = {
      modalities: ['text', 'audio'],
      instructions: this.getInstructions(),
      voice: this.config.voice || 'alloy',
      input_audio_format: 'pcm16',
      output_audio_format: 'pcm16',
      input_audio_transcription: {
        model: 'whisper-1'
      },
      // üîß NOVO: Configura√ß√£o otimizada de VAD para conversa√ß√£o natural
      turn_detection: {
        type: 'server_vad',
        threshold: 0.6, // Aumentado para reduzir falsos positivos
        prefix_padding_ms: 500, // Aumentado para capturar in√≠cio da fala
        silence_duration_ms: 800, // Aumentado para permitir pausas naturais
        create_response: true
      },
      tools: this.getEnglishLearningTools(),
      tool_choice: 'auto',
      temperature: 0.8,
      max_response_output_tokens: 4096
    };

    console.log('üì§ [FIXED] Sending session update:', sessionConfig);
    
    // ‚úÖ Enviar session.update (n√£o criar ephemeral session)
    this.sendEvent({
      type: 'session.update',
      session: sessionConfig
    });
  }

  // üìã Instru√ß√µes por n√≠vel - VERS√ÉO CORRIGIDA
  private getInstructions(): string {
    const levelInstructions = {
      'Novice': `CRITICAL: You must speak only in English. Never mix Portuguese and English in the same response.

You are Charlotte, a friendly and patient English tutor for Brazilian beginners who are just starting their English journey.

SPEAKING GUIDELINES:
- Always speak in English only
- Speak slowly and clearly with simple pronunciation
- Use basic vocabulary and short, simple sentences
- Pause between sentences to give time for understanding
- If a student seems confused about a specific word, you may briefly add the Portuguese translation in parentheses like: "That's wonderful (maravilhoso)!"
- Keep responses conversational and encouraging

TEACHING APPROACH:
- Always celebrate small victories and progress
- Focus on building confidence and reducing anxiety about speaking English
- Use positive reinforcement frequently
- Ask simple, encouraging questions to keep the conversation flowing
- Help with basic grammar and pronunciation in a gentle way
- Make English feel fun and accessible, not intimidating

CONVERSATION STYLE:
- Be warm, patient, and encouraging
- Use everyday topics and situations
- Keep conversations natural and relaxed
- Show genuine interest in what the student is saying`,

      'Intermediate': `CRITICAL: You must speak only in English. Never use Portuguese.

You are Charlotte, an English tutor for intermediate Brazilian learners who have a good foundation in English.

SPEAKING GUIDELINES:
- Always speak in English only - no Portuguese at all
- Use clear, natural English at a moderate pace
- Employ varied vocabulary and more complex sentence structures
- Speak with natural rhythm and intonation
- Challenge the student appropriately without overwhelming them

TEACHING APPROACH:
- Help with practical conversation skills and real-world situations
- Focus on fluency and natural conversation flow
- Provide corrections in a friendly, constructive way
- Introduce idioms, expressions, and cultural references
- Help refine grammar and expand vocabulary naturally through conversation
- Encourage longer, more detailed responses

CONVERSATION STYLE:
- Be engaging and intellectually stimulating
- Discuss current events, culture, travel, work, and personal interests
- Ask thoughtful follow-up questions
- Help bridge the gap between textbook English and real-world communication
- Build confidence for professional and social situations`,

      'Advanced': `CRITICAL: You must speak only in English. Never use Portuguese.

You are Charlotte, an English tutor for advanced Brazilian learners who want to achieve native-like fluency.

SPEAKING GUIDELINES:
- Always speak in English only - no Portuguese at all
- Use sophisticated vocabulary and natural native-like speech patterns
- Speak at natural native speed with complex sentence structures
- Use cultural references, idioms, and colloquialisms naturally
- Challenge the student with nuanced language and advanced concepts

TEACHING APPROACH:
- Help refine pronunciation to achieve native-like accent
- Focus on subtle grammar points and advanced language features
- Discuss complex topics requiring sophisticated language skills
- Help with professional communication and academic language
- Provide feedback on style, register, and cultural appropriateness
- Challenge the student to express complex ideas with precision

CONVERSATION STYLE:
- Be intellectually challenging and culturally rich
- Engage in sophisticated discussions about complex topics
- Use humor, cultural references, and advanced language naturally
- Help the student sound like a native speaker in all contexts
- Focus on achieving true bilingual proficiency`
    };
    
    return this.config.instructions || levelInstructions[this.config.userLevel];
  }

  // üõ†Ô∏è Ferramentas de ensino
  private getEnglishLearningTools(): any[] {
    return [
      {
        type: 'function',
        name: 'get_word_definition',
        description: 'Get definition and examples of an English word',
        parameters: {
          type: 'object',
          properties: {
            word: { type: 'string', description: 'The English word to define' },
            level: { 
              type: 'string', 
              enum: ['Novice', 'Intermediate', 'Advanced'],
              description: 'Learner level for appropriate explanation'
            }
          },
          required: ['word', 'level']
        }
      },
      {
        type: 'function',
        name: 'check_pronunciation',
        description: 'Provide pronunciation feedback',
        parameters: {
          type: 'object',
          properties: {
            text: { type: 'string', description: 'The text that was spoken' },
            target_word: { type: 'string', description: 'Word or phrase being practiced' }
          },
          required: ['text', 'target_word']
        }
      }
    ];
  }

  // üì§ Enviar evento para WebSocket
  private sendEvent(event: any): void {
    if (this.ws && this.isConnected && this.ws.readyState === WebSocket.OPEN) {
      const eventString = JSON.stringify(event);
      console.log('üì§ [FIXED] Sending event:', event.type);
      this.ws.send(eventString);
    } else {
      console.warn('‚ö†Ô∏è [FIXED] Cannot send event - WebSocket not connected', {
        hasWs: !!this.ws,
        isConnected: this.isConnected,
        readyState: this.ws?.readyState
      });
    }
  }

  // üì• Processar mensagens (igual ao anterior, mas com logs melhorados)
  private handleMessage(data: string): void {
    try {
      const event: RealtimeEvent = JSON.parse(data);
      console.log('üì• [FIXED] Received event:', event.type);
      
      switch (event.type) {
        case 'session.created':
          console.log('‚úÖ [FIXED] Session created successfully');
          this.sessionId = event.session?.id;
          this.emit('session_created', event);
          break;

        case 'session.updated':
          console.log('üîÑ [FIXED] Session updated');
          this.emit('session_updated', event);
          break;

        case 'input_audio_buffer.speech_started':
          console.log('üé§ [FIXED] User started speaking');
          this.emit('user_speech_started', event);
          break;

        case 'input_audio_buffer.speech_stopped':
          console.log('üîá [FIXED] User stopped speaking');
          this.emit('user_speech_stopped', event);
          break;

        case 'conversation.item.created':
          console.log('üí¨ [FIXED] Conversation item created:', event.item?.type);
          this.emit('conversation_item_created', event);
          
          if (event.item?.type === 'function_call') {
            this.handleFunctionCall(event.item);
          }
          break;

        case 'conversation.item.input_audio_transcription.completed':
          console.log('üìù [FIXED] Transcription completed:', event.transcript);
          this.emit('input_transcription_completed', event);
          // üîß NOVO: Analisar transcri√ß√£o para ajustar VAD
          if (event.transcript) {
            this.handleShortWordDetection(event.transcript);
          }
          break;

        case 'response.created':
          console.log('ü§ñ [FIXED] Response created');
          this.emit('response_created', event);
          break;

        case 'response.text.delta':
          this.emit('text_delta', event);
          break;

        case 'response.text.done':
          console.log('‚úÖ [FIXED] Text response completed');
          this.emit('text_done', event);
          break;

        case 'response.audio.delta':
          console.log('üîä [FIXED] Audio delta received, queue length:', this.audioQueue.length, 'isPlaying:', this.isPlayingAudio);
          this.emit('audio_delta', event);
          if (event.delta) {
            this.playAudio(event.delta);
          }
          break;

        case 'response.audio.done':
          console.log('‚úÖ [FIXED] Audio response completed');
          this.emit('audio_done', event);
          break;

        case 'response.done':
          console.log('‚úÖ [FIXED] Response completed');
          this.emit('response_done', event);
          break;

        case 'error':
          console.error('‚ùå [FIXED] API Error:', event.error);
          this.emit('error', event);
          break;

        default:
          console.log('üì® [FIXED] Unhandled event:', event.type);
          this.emit('unhandled_event', event);
      }
    } catch (error) {
      console.error('‚ùå [FIXED] Error parsing message:', error);
      this.emit('error', { error: { message: 'Failed to parse message', details: error } });
    }
  }

  // üîß Tratar chamadas de fun√ß√£o
  private handleFunctionCall(item: any): void {
    const functionName = item.name;
    const args = JSON.parse(item.arguments || '{}');
    
    console.log('üîß [FIXED] Function call:', functionName, args);
    
    let result = '';
    
    switch (functionName) {
      case 'get_word_definition':
        result = JSON.stringify({
          word: args.word,
          definition: `Definition of "${args.word}" for ${args.level} level`,
          examples: [`Example with ${args.word}.`],
          pronunciation: `/pronunciation-guide/`
        });
        break;
        
      case 'check_pronunciation':
        result = JSON.stringify({
          accuracy: 85,
          feedback: 'Good pronunciation! Try emphasizing the first syllable more.',
          suggestions: ['Practice slowly', 'Focus on clarity']
        });
        break;
        
      default:
        result = JSON.stringify({ error: 'Function not implemented' });
    }
    
    this.sendFunctionResult(item.call_id, result);
  }

  // üé§ Inicializar √°udio (simplificado)
  async initializeAudio(): Promise<void> {
    try {
      console.log('üé§ [FIXED] Initializing high-quality audio...');
      
      // üîß NOVO: Configura√ß√µes otimizadas para alta qualidade
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 24000, // Mant√©m 24kHz para compatibilidade
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
          // Configura√ß√µes avan√ßadas removidas para compatibilidade TypeScript
        }
      });

      // üîß NOVO: AudioContext com configura√ß√µes otimizadas
      this.audioContext = new AudioContext({ 
        sampleRate: 24000,
        latencyHint: 'interactive' // Otimizado para baixa lat√™ncia
      });
      
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
      }
      
      // üîä NOVO: Criar GainNode para controle de volume com compressor
      this.audioGainNode = this.audioContext.createGain();
      this.audioGainNode.gain.value = 1.0; // Volume normal
      
      // üîß NOVO: Adicionar compressor din√¢mico para melhor qualidade
      const compressor = this.audioContext.createDynamicsCompressor();
      compressor.threshold.setValueAtTime(-24, this.audioContext.currentTime);
      compressor.knee.setValueAtTime(30, this.audioContext.currentTime);
      compressor.ratio.setValueAtTime(12, this.audioContext.currentTime);
      compressor.attack.setValueAtTime(0.003, this.audioContext.currentTime);
      compressor.release.setValueAtTime(0.25, this.audioContext.currentTime);
      
      // üîß NOVO: Cadeia de processamento de √°udio otimizada
      this.audioGainNode.connect(compressor);
      compressor.connect(this.audioContext.destination);
      
      // üîß NOVO: Processamento de entrada otimizado
      const source = this.audioContext.createMediaStreamSource(this.mediaStream);
      
      // üîß NOVO: Usar AudioWorklet se dispon√≠vel, sen√£o ScriptProcessor
      if (this.audioContext.audioWorklet) {
        // Implementa√ß√£o futura com AudioWorklet para melhor performance
        console.log('üé§ AudioWorklet available but using ScriptProcessor for compatibility');
      }
      
      // üîß MELHORADO: ScriptProcessor com buffer otimizado
      const processor = this.audioContext.createScriptProcessor(2048, 1, 1); // Buffer menor para menor lat√™ncia
      
      processor.onaudioprocess = (event) => {
        const inputBuffer = event.inputBuffer;
        const inputData = inputBuffer.getChannelData(0);
        
        // üîß NOVO: Processamento de √°udio melhorado com normaliza√ß√£o
        const normalizedData = new Float32Array(inputData.length);
        let maxAmplitude = 0;
        
        // Encontrar amplitude m√°xima
        for (let i = 0; i < inputData.length; i++) {
          const amplitude = Math.abs(inputData[i]);
          if (amplitude > maxAmplitude) {
            maxAmplitude = amplitude;
          }
        }
        
        // Normalizar e converter para Int16
        const int16Array = new Int16Array(inputData.length);
        const normalizationFactor = maxAmplitude > 0 ? 0.95 / maxAmplitude : 1;
        
        for (let i = 0; i < inputData.length; i++) {
          const normalizedSample = inputData[i] * normalizationFactor;
          int16Array[i] = Math.max(-32768, Math.min(32767, normalizedSample * 32768));
        }
        
        this.sendAudioData(int16Array);
      };
      
      source.connect(processor);
      processor.connect(this.audioContext.destination);

      console.log('‚úÖ [FIXED] High-quality audio initialized successfully');
      this.emit('audio_initialized');

    } catch (error) {
      console.error('‚ùå [FIXED] Failed to initialize audio:', error);
      throw error;
    }
  }

  // üì§ Enviar dados de √°udio
  private sendAudioData(audioData: Int16Array): void {
    if (!this.isConnected || this.ws?.readyState !== WebSocket.OPEN) return;

    try {
      const base64Audio = this.arrayBufferToBase64(audioData.buffer as ArrayBuffer);
      
      this.sendEvent({
        type: 'input_audio_buffer.append',
        audio: base64Audio
      });
    } catch (error) {
      console.error('‚ùå [FIXED] Error sending audio:', error);
    }
  }

  // üîÑ Utilit√°rios de convers√£o
  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  private base64ToArrayBuffer(base64: string): ArrayBuffer {
    const binaryString = atob(base64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  }

  // üîä NOVO: Sistema de reprodu√ß√£o de √°udio com fila (evita duplica√ß√£o)
  private playAudio(base64Audio: string): void {
    if (!this.audioContext || !this.audioGainNode) return;

    // Adicionar √† fila
    this.audioQueue.push(base64Audio);
    
    // Se n√£o estiver reproduzindo, iniciar reprodu√ß√£o
    if (!this.isPlayingAudio) {
      this.processAudioQueue();
    }
  }

  // üîä NOVO: Processar fila de √°udio sequencialmente
  private async processAudioQueue(): Promise<void> {
    if (this.audioQueue.length === 0 || this.isPlayingAudio) {
      return;
    }

    this.isPlayingAudio = true;

    while (this.audioQueue.length > 0) {
      const base64Audio = this.audioQueue.shift();
      if (!base64Audio) continue;

      try {
        await this.playAudioChunk(base64Audio);
      } catch (error) {
        console.error('‚ùå [FIXED] Error playing audio chunk:', error);
      }
    }

    this.isPlayingAudio = false;
  }

  // üîä NOVO: Reproduzir um chunk de √°udio
  private playAudioChunk(base64Audio: string): Promise<void> {
    return new Promise((resolve, reject) => {
      if (!this.audioContext || !this.audioGainNode) {
        reject(new Error('Audio context not available'));
        return;
      }

      try {
        const audioBuffer = this.base64ToArrayBuffer(base64Audio);
        const audioData = new Int16Array(audioBuffer);
        
        // üîß NOVO: Processamento de √°udio melhorado com anti-aliasing
        const floatArray = new Float32Array(audioData.length);
        
        // Converter Int16 para Float32 com normaliza√ß√£o suave
        for (let i = 0; i < audioData.length; i++) {
          floatArray[i] = audioData[i] / 32768.0;
        }
        
        // üîß NOVO: Aplicar suaviza√ß√£o nas bordas para evitar estalidos
        const fadeLength = Math.min(256, Math.floor(floatArray.length * 0.01)); // 1% ou 256 samples
        
        // Fade-in no in√≠cio
        for (let i = 0; i < fadeLength; i++) {
          const fadeMultiplier = i / fadeLength;
          floatArray[i] *= fadeMultiplier;
        }
        
        // Fade-out no final
        for (let i = floatArray.length - fadeLength; i < floatArray.length; i++) {
          const fadeMultiplier = (floatArray.length - 1 - i) / fadeLength;
          floatArray[i] *= fadeMultiplier;
        }

        // üîß NOVO: Criar buffer com configura√ß√µes otimizadas
        const buffer = this.audioContext.createBuffer(1, floatArray.length, 24000);
        buffer.copyToChannel(floatArray, 0);

        // üõë IMPORTANTE: Parar √°udio anterior se existir
        if (this.currentAudioSource) {
          try {
            this.currentAudioSource.stop();
            this.currentAudioSource.disconnect();
          } catch (e) {
            // Ignorar erros de stop em sources j√° finalizados
          }
        }

        const source = this.audioContext.createBufferSource();
        source.buffer = buffer;
        
        // üîß NOVO: Configura√ß√µes otimizadas para qualidade
        source.playbackRate.value = 1.0; // Taxa de reprodu√ß√£o normal
        
        // üîß NOVO: Conectar atrav√©s de filtro passa-baixa para suavizar
        const lowPassFilter = this.audioContext.createBiquadFilter();
        lowPassFilter.type = 'lowpass';
        lowPassFilter.frequency.setValueAtTime(12000, this.audioContext.currentTime); // Cortar frequ√™ncias muito altas
        lowPassFilter.Q.setValueAtTime(0.7, this.audioContext.currentTime);
        
        // üîß NOVO: Cadeia de processamento otimizada
        source.connect(lowPassFilter);
        lowPassFilter.connect(this.audioGainNode);
        
        // Armazenar refer√™ncia para controle
        this.currentAudioSource = source;

        source.onended = () => {
          this.currentAudioSource = null;
          resolve();
        };

        // üîß NOVO: Iniciar com timing preciso
        const startTime = this.audioContext.currentTime + 0.01; // Pequeno delay para estabilidade
        source.start(startTime);

      } catch (error) {
        console.error('‚ùå [FIXED] Error playing audio chunk:', error);
        reject(error);
      }
    });
  }

  // üõë NOVO: Parar reprodu√ß√£o de √°udio
  private stopCurrentAudio(): void {
    if (this.currentAudioSource) {
      try {
        this.currentAudioSource.stop();
        this.currentAudioSource.disconnect();
      } catch (e) {
        // Ignorar erros
      }
      this.currentAudioSource = null;
    }
    
    // Limpar fila
    this.audioQueue = [];
    this.isPlayingAudio = false;
  }

  // üéß Sistema de eventos
  on(eventType: string, callback: Function): void {
    if (!this.eventListeners.has(eventType)) {
      this.eventListeners.set(eventType, []);
    }
    this.eventListeners.get(eventType)!.push(callback);
  }

  off(eventType: string, callback: Function): void {
    const listeners = this.eventListeners.get(eventType);
    if (listeners) {
      const index = listeners.indexOf(callback);
      if (index > -1) {
        listeners.splice(index, 1);
      }
    }
  }

  private emit(eventType: string, data?: any): void {
    const listeners = this.eventListeners.get(eventType);
    if (listeners) {
      listeners.forEach(callback => {
        try {
          callback(data);
        } catch (error) {
          console.error('‚ùå [FIXED] Error in event listener:', error);
        }
      });
    }
  }

  // üé§ Fun√ß√µes de controle
  createResponse(): void {
    this.sendEvent({
      type: 'response.create',
      response: {
        modalities: ['text', 'audio'],
        instructions: `Respond naturally as Charlotte, adapting to the user's ${this.config.userLevel} level.`
      }
    });
  }

  // üîß NOVO: Interrup√ß√£o inteligente com controle de VAD
  interruptResponse(): void {
    console.log('üõë [FIXED] Intelligent interruption triggered');
    
    // üõë NOVO: Parar √°udio atual antes de cancelar resposta
    this.stopCurrentAudio();
    
    // üîß NOVO: Ajustar temporariamente o VAD para ser menos sens√≠vel ap√≥s interrup√ß√£o
    this.adjustVADSensitivity('post_interruption');
    
    this.sendEvent({
      type: 'response.cancel'
    });
    
    // üîß NOVO: Restaurar VAD ap√≥s um tempo
    setTimeout(() => {
      this.adjustVADSensitivity('normal');
    }, 2000);
  }

  // üîß NOVO: Ajustar sensibilidade do VAD dinamicamente
  private adjustVADSensitivity(mode: 'normal' | 'post_interruption' | 'sensitive'): void {
    let vadConfig;
    
    switch (mode) {
      case 'post_interruption':
        vadConfig = {
          type: 'server_vad',
          threshold: 0.7, // Mais alto ap√≥s interrup√ß√£o
          prefix_padding_ms: 300,
          silence_duration_ms: 1200, // Mais tempo para evitar re-interrup√ß√µes
          create_response: true
        };
        break;
        
      case 'sensitive':
        vadConfig = {
          type: 'server_vad',
          threshold: 0.4, // Mais sens√≠vel para capturar palavras curtas
          prefix_padding_ms: 600,
          silence_duration_ms: 600,
          create_response: true
        };
        break;
        
      default: // normal
        vadConfig = {
          type: 'server_vad',
          threshold: 0.6,
          prefix_padding_ms: 500,
          silence_duration_ms: 800,
          create_response: true
        };
    }
    
    console.log(`üîß [FIXED] Adjusting VAD to ${mode} mode:`, vadConfig);
    
    this.sendEvent({
      type: 'session.update',
      session: {
        turn_detection: vadConfig
      }
    });
  }

  // üîß NOVO: Detectar palavras curtas e ajustar VAD
  private handleShortWordDetection(transcript: string): void {
    const shortWords = ['yes', 'no', 'ok', 'yeah', 'nah', 'sure', 'right', 'good', 'bad', 'hi', 'bye'];
    const words = transcript.toLowerCase().split(' ');
    
    if (words.length <= 2 && words.some(word => shortWords.includes(word))) {
      console.log('üîß [FIXED] Short word detected, adjusting VAD sensitivity');
      this.adjustVADSensitivity('sensitive');
      
      // Restaurar ap√≥s 5 segundos
      setTimeout(() => {
        this.adjustVADSensitivity('normal');
      }, 5000);
    }
  }

  sendFunctionResult(callId: string, output: string): void {
    this.sendEvent({
      type: 'conversation.item.create',
      item: {
        type: 'function_call_output',
        call_id: callId,
        output: output
      }
    });
  }

  sendTextMessage(text: string): void {
    this.sendEvent({
      type: 'conversation.item.create',
      item: {
        type: 'message',
        role: 'user',
        content: [{ type: 'input_text', text: text }]
      }
    });
    this.createResponse();
  }

  commitAudio(): void {
    this.sendEvent({
      type: 'input_audio_buffer.commit'
    });
    this.createResponse();
  }

  clearAudioBuffer(): void {
    this.sendEvent({
      type: 'input_audio_buffer.clear'
    });
  }

  // üîå Limpeza e desconex√£o
  disconnect(): void {
    console.log('üîå [FIXED] Disconnecting...');
    
    // üõë NOVO: Parar √°udio atual e limpar fila
    this.stopCurrentAudio();
    
    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach(track => track.stop());
      this.mediaStream = null;
    }

    if (this.audioGainNode) {
      this.audioGainNode.disconnect();
      this.audioGainNode = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    if (this.ws) {
      this.ws.close(1000, 'Client disconnecting');
      this.ws = null;
    }

    this.isConnected = false;
    this.sessionId = null;
    this.reconnectAttempts = 0;
    this.eventListeners.clear();
    
    console.log('‚úÖ [FIXED] Disconnected successfully');
  }

  // üìä Getters
  get connected(): boolean {
    return this.isConnected && this.ws?.readyState === WebSocket.OPEN;
  }

  get session(): string | null {
    return this.sessionId;
  }

  // üîç M√©todo de diagn√≥stico
  async diagnose(): Promise<any> {
    console.log('üîç [FIXED] Running connection diagnosis...');
    
    const diagnosis = {
      timestamp: new Date().toISOString(),
      apiKeyConfigured: !!this.config.apiKey,
      apiKeyLength: this.config.apiKey?.length || 0,
      websocketSupport: typeof WebSocket !== 'undefined',
      audioSupport: !!navigator.mediaDevices?.getUserMedia,
      connectionState: this.ws?.readyState,
      isConnected: this.isConnected,
      sessionId: this.sessionId,
      reconnectAttempts: this.reconnectAttempts
    };

    console.log('üìä [FIXED] Diagnosis:', diagnosis);
    return diagnosis;
  }
}

// üöÄ Fun√ß√£o de conveni√™ncia para uso simplificado
export async function createRealtimeConnection(config: RealtimeConfig): Promise<OpenAIRealtimeService> {
  const service = new OpenAIRealtimeService(config);
  
  try {
    await service.connect();
    await service.initializeAudio();
    return service;
  } catch (error) {
    console.error('‚ùå [FIXED] Failed to create Realtime connection:', error);
    throw error;
  }
}

// üîß Fun√ß√£o para verificar se a conta tem acesso √† Realtime API
export async function checkRealtimeAccess(): Promise<{
  hasAccess: boolean;
  models: string[];
  error?: string;
}> {
  try {
    const response = await fetch('/api/realtime-token', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        userLevel: 'Intermediate',
        userName: 'Access Check',
        debug: true
      })
    });

    if (!response.ok) {
      return {
        hasAccess: false,
        models: [],
        error: `Token API failed: ${response.status}`
      };
    }

    const data = await response.json();
    
    if (!data.success) {
      return {
        hasAccess: false,
        models: [],
        error: data.error || 'Unknown error'
      };
    }

    // Se chegou at√© aqui, provavelmente tem acesso
    return {
      hasAccess: true,
      models: ['gpt-4o-realtime-preview-2024-10-01'],
      error: undefined
    };

  } catch (error: any) {
    return {
      hasAccess: false,
      models: [],
      error: error.message
    };
  }
}

export default OpenAIRealtimeService;